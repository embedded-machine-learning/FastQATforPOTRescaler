{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "muslim-selection",
      "metadata": {
        "id": "muslim-selection"
      },
      "source": [
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# ResNet\n",
        "\n",
        "*Author: Pytorch Team*\n",
        "\n",
        "**Deep residual networks pre-trained on ImageNet**\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/resnet.png\" alt=\"alt\" width=\"50%\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "exempt-potter",
      "metadata": {
        "id": "exempt-potter"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/dschnoell/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from model.resnet.resnet import resnet18\n",
        "\n",
        "model_troch = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "# or any of these variants\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
        "\n",
        "model = resnet18(False)\n",
        "model.load_state_dict(model_troch.state_dict(),strict=False)\n",
        "\n",
        "# model = model_troch\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "critical-former",
      "metadata": {
        "id": "critical-former"
      },
      "source": [
        "All pre-trained models expect input images normalized in the same way,\n",
        "i.e. mini-batches of 3-channel RGB images of shape `(3 x H x W)`, where `H` and `W` are expected to be at least `224`.\n",
        "The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n",
        "and `std = [0.229, 0.224, 0.225]`.\n",
        "\n",
        "Here's a sample execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "inclusive-blank",
      "metadata": {
        "id": "inclusive-blank"
      },
      "outputs": [],
      "source": [
        "# Download an example image from the pytorch website\n",
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "occupational-japanese",
      "metadata": {
        "id": "occupational-japanese"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 1.6348e-02, -1.5493e+00,  3.2135e-01, -2.0588e+00, -8.5830e-01,\n",
            "         1.7866e+00,  1.4709e+00,  2.1619e+00,  4.4877e+00,  8.2917e-01,\n",
            "        -5.7816e+00, -3.4980e+00, -4.0627e+00, -4.7541e+00, -3.8073e+00,\n",
            "        -4.7246e+00, -1.2612e+00,  2.9666e-01, -2.0489e+00, -5.3125e-01,\n",
            "        -3.5982e+00, -8.1681e-01, -2.7672e+00, -1.2787e+00, -3.4198e+00,\n",
            "        -1.9048e+00, -3.0007e+00, -1.3459e+00, -1.8379e+00,  1.3942e+00,\n",
            "        -2.0110e+00, -1.4147e+00, -2.3274e+00, -1.8204e+00, -1.1751e-01,\n",
            "        -3.4102e+00, -1.6540e+00, -3.4500e+00, -2.6464e+00, -2.7412e+00,\n",
            "        -2.2204e+00, -3.6512e+00, -4.1241e+00, -5.5941e+00, -1.7524e+00,\n",
            "        -1.6916e+00, -9.8194e-01, -2.1235e+00, -3.5170e+00, -1.3325e+00,\n",
            "        -1.1344e+00, -1.1556e+00, -2.2247e-02, -8.5877e-01, -1.2915e+00,\n",
            "        -2.8691e+00,  6.6023e-01, -1.7168e+00, -1.2442e+00, -2.3364e+00,\n",
            "        -5.8312e-02, -1.9207e+00, -2.5965e+00, -1.8021e+00, -1.5122e+00,\n",
            "        -1.0853e+00, -4.0834e-01, -1.3090e+00, -9.4037e-01, -4.0605e+00,\n",
            "        -1.9035e+00, -6.0958e-01, -2.3419e+00, -2.5521e+00, -2.7559e+00,\n",
            "        -2.1571e+00, -3.0428e+00, -3.8195e+00,  1.9953e+00,  8.0758e-01,\n",
            "        -2.8859e+00, -4.6351e-01, -1.9107e+00, -1.8594e+00, -1.9936e-01,\n",
            "        -7.4778e-01, -2.3915e+00, -1.1247e+00, -2.0495e+00,  2.2916e+00,\n",
            "        -2.6377e+00, -3.6727e+00, -4.7539e+00, -2.8072e+00, -1.9323e+00,\n",
            "        -4.6473e+00, -2.5208e+00, -2.4857e+00, -3.0074e+00, -4.8832e-01,\n",
            "        -9.3518e-01, -2.6050e+00,  2.1383e+00, -2.6335e+00,  8.3531e+00,\n",
            "         8.9800e-01,  3.7540e+00, -3.4337e+00, -1.8979e+00, -4.2955e+00,\n",
            "         2.9123e-01, -2.3304e+00,  2.3846e+00,  4.3126e-02,  2.2361e-01,\n",
            "         7.5330e-01, -3.3077e+00, -1.4769e+00, -1.1788e+00, -1.9238e+00,\n",
            "        -1.8423e+00, -1.2768e+00, -1.0864e+00, -9.9673e-01,  1.5154e-01,\n",
            "        -1.4343e+00, -1.8035e+00,  1.0721e+00, -1.8641e+00,  2.6239e-01,\n",
            "        -1.5029e+00, -4.6535e+00, -1.9523e+00, -6.8748e+00, -1.6441e+00,\n",
            "        -3.2267e+00, -3.2739e+00, -3.8385e+00, -2.1763e+00, -3.5056e+00,\n",
            "        -4.7003e+00, -3.6277e+00, -4.8833e+00, -1.9912e+00,  2.6385e-01,\n",
            "        -6.7378e-01,  9.3558e-01, -2.2407e+00, -2.1349e+00, -4.7886e-01,\n",
            "        -2.6297e-01,  5.0752e+00,  4.4921e+00,  5.3018e+00,  5.1155e+00,\n",
            "         1.0424e+00,  5.4929e-02,  5.7178e+00,  2.8048e+00, -6.5453e-01,\n",
            "         7.1659e-01, -1.0815e+00, -8.4665e-01, -1.4038e+00, -4.8348e-01,\n",
            "        -4.0577e+00,  2.1711e-02, -1.7141e+00, -2.5330e-01,  5.0027e+00,\n",
            "         6.5755e+00,  3.8570e-01,  1.3989e-01,  3.1361e+00,  6.6814e+00,\n",
            "         2.2439e+00,  4.6576e-01,  3.2964e+00, -8.5069e-01,  1.1055e+00,\n",
            "         1.6827e+00,  3.0317e-02,  2.7665e+00,  1.0103e+00,  3.2920e+00,\n",
            "         6.0676e+00,  7.0718e+00,  5.1730e-01,  3.6326e+00,  2.7668e+00,\n",
            "         3.2237e+00, -9.3719e-01,  6.9497e+00,  4.2845e+00,  2.6176e+00,\n",
            "         1.6060e+00,  4.3795e-01,  1.0892e+00, -3.5243e-01,  6.1576e+00,\n",
            "         2.6475e+00,  1.6075e+00,  2.6785e+00,  1.0351e+01,  2.5245e+00,\n",
            "         8.3480e-01, -1.3499e+00,  5.1932e+00,  2.9656e+00, -5.6637e-01,\n",
            "        -1.4320e+00,  2.9176e-02,  2.4525e+00,  3.0385e-01, -7.7763e-01,\n",
            "         1.6606e+00,  1.9858e+00,  2.0593e+00,  2.6866e-01, -1.8826e-01,\n",
            "         2.7442e-01, -1.7499e+00,  8.8929e+00,  8.1122e+00,  7.3253e+00,\n",
            "         2.8655e+00,  3.7858e+00,  4.1995e+00,  5.8172e+00,  6.1470e+00,\n",
            "         6.4166e+00,  7.6102e+00,  6.9845e+00,  2.9960e+00, -5.2738e-01,\n",
            "         5.5977e+00,  1.4412e+00, -3.9534e-01,  2.0420e+00,  1.8695e+00,\n",
            "         2.0420e+00,  2.0347e-01,  6.4379e-01, -4.0696e-01,  2.5670e+00,\n",
            "         1.2411e+00,  1.4617e+00,  4.1675e+00,  1.0819e+01,  8.7373e+00,\n",
            "         9.9061e+00,  2.8375e+00,  2.0206e-01,  1.7978e+00,  2.3160e+00,\n",
            "         2.5299e+00,  4.5023e+00,  1.1026e+01,  1.6275e+01,  1.1214e+01,\n",
            "         7.8103e+00,  1.0740e+01, -1.0011e-01,  5.7140e+00,  4.7228e+00,\n",
            "         3.3946e+00,  3.0948e+00,  3.8407e+00, -8.0349e-01,  8.1761e+00,\n",
            "         1.3281e+01,  3.4675e+00,  4.4458e+00,  5.5256e+00,  4.1518e+00,\n",
            "        -1.9290e-01,  1.3227e+00,  5.0947e+00,  4.9228e+00,  1.3313e+01,\n",
            "         4.6694e+00,  4.1273e+00,  3.8478e+00,  6.4165e+00,  6.1105e+00,\n",
            "         3.3085e+00,  2.3566e+00,  6.8444e+00,  9.5449e-01,  2.8575e+00,\n",
            "        -1.1251e+00,  1.5093e+00,  1.7632e+00,  1.2525e+00,  2.8588e+00,\n",
            "         1.7493e+00,  6.7812e+00,  2.5375e-01, -1.3365e+00,  5.0928e-01,\n",
            "        -2.8961e+00, -8.2367e-01, -2.9126e+00, -3.0456e+00, -1.1138e+00,\n",
            "        -2.8025e+00, -1.4493e+00, -6.7313e-01, -4.2259e+00, -1.7623e+00,\n",
            "         4.3737e-01, -1.4015e+00, -1.5383e+00, -1.5601e+00,  1.6330e+00,\n",
            "        -2.3884e+00, -2.9766e+00, -4.3829e-01, -5.5063e-01, -6.1549e+00,\n",
            "        -4.0847e+00, -2.3557e+00, -3.9525e+00, -2.8769e+00, -4.5148e-01,\n",
            "        -1.7369e+00, -1.6379e+00,  2.1366e+00, -8.5101e-01, -1.5172e-02,\n",
            "         2.7711e+00,  5.3785e+00,  5.9550e+00,  5.4223e+00,  2.8865e+00,\n",
            "         3.7562e-01,  1.6290e+00,  4.4573e-01,  3.2406e+00,  9.7767e-01,\n",
            "         2.6052e-02,  3.1058e+00, -2.6925e-01, -2.7831e+00, -3.1685e+00,\n",
            "         8.1549e-01, -6.5104e-01, -2.9611e+00,  2.6036e+00, -9.6843e-01,\n",
            "        -9.5567e-01, -4.7054e+00, -3.5801e+00,  2.2954e-01, -2.1682e+00,\n",
            "         6.5014e+00,  5.7213e+00,  2.9800e+00,  6.4612e+00,  5.4975e+00,\n",
            "        -5.3028e-01,  4.7047e+00,  2.8003e+00, -3.3512e-03, -1.3495e+00,\n",
            "        -4.5668e-01, -5.6225e-01, -1.6321e+00,  2.1300e+00, -1.4559e+00,\n",
            "        -2.3866e-03,  9.0514e-01,  1.6596e+00,  2.0629e+00,  1.0825e+00,\n",
            "        -8.2108e-01, -3.6817e+00,  2.5448e+00,  1.4178e+00,  5.3899e-01,\n",
            "         1.0834e+00, -9.5496e-02,  4.6164e-01,  1.0737e+00,  7.6368e-02,\n",
            "        -2.6607e+00, -4.3080e+00,  3.6670e+00,  5.1784e+00, -6.1720e-01,\n",
            "        -1.5430e+00,  7.3490e-01, -3.7431e+00, -2.9982e+00, -5.4735e-01,\n",
            "        -1.9196e+00, -3.7730e+00, -2.9877e+00, -9.2497e-01, -4.2614e-01,\n",
            "        -8.8867e-01, -5.8453e-01, -6.5388e-01, -4.9162e+00, -2.8369e+00,\n",
            "         3.4218e-01, -2.2508e+00, -2.7391e-01, -2.4036e+00, -5.2707e-01,\n",
            "        -2.6053e+00,  3.2458e-01,  4.0660e+00, -2.1192e+00, -5.1591e-01,\n",
            "        -1.7742e+00, -2.0593e+00, -6.6476e-01, -1.4373e+00,  9.8572e-01,\n",
            "         7.0718e-03, -9.6718e-01, -6.0143e-01, -1.4012e+00, -2.0723e+00,\n",
            "         1.1083e+00, -1.9486e+00,  2.2071e+00,  2.9284e+00,  1.8652e+00,\n",
            "        -2.8892e+00, -4.3106e-01, -1.3995e+00, -3.7392e-01,  7.7563e-01,\n",
            "         3.9191e+00, -7.5840e-01, -1.8528e-01, -1.6252e+00,  2.2088e+00,\n",
            "         1.5948e+00,  7.0023e-02,  3.9126e-01,  4.6391e-01,  5.8984e-01,\n",
            "        -9.4137e-02, -5.1497e-01, -1.3633e+00, -1.5011e-01, -5.6837e-01,\n",
            "         2.4677e+00, -1.7121e+00, -1.6868e+00, -3.2714e-01, -8.4342e-01,\n",
            "         2.1158e+00, -8.3095e-02,  1.7846e+00, -6.3505e-01, -7.4831e-01,\n",
            "         4.2879e-01, -5.1161e-01,  3.4117e+00,  5.7126e+00, -1.2796e+00,\n",
            "        -1.6482e+00, -2.5273e+00, -3.1733e+00, -1.0116e+00,  9.4715e-01,\n",
            "         9.9314e-01, -1.0923e-01,  2.5846e+00,  1.4924e+00, -1.2990e+00,\n",
            "        -2.8259e-01, -8.6453e-01, -1.4784e-01,  1.7303e+00,  2.4505e+00,\n",
            "        -7.3569e-01, -2.5547e+00, -1.9147e+00,  1.7078e-01,  3.2668e-01,\n",
            "        -1.3443e+00, -1.5299e+00, -7.6644e-01, -7.8749e-01,  1.0067e+00,\n",
            "        -1.2134e+00,  1.4811e+00, -2.7442e-01, -1.3604e+00, -1.7607e-01,\n",
            "        -1.1740e+00,  2.3963e+00, -6.8032e-01, -2.6911e+00,  7.7301e-02,\n",
            "        -3.4518e+00,  1.2129e+00,  1.2676e+00, -1.1012e+00,  2.7961e-01,\n",
            "        -9.9984e-01, -2.0032e+00,  7.5339e-01,  2.4310e+00, -1.7249e+00,\n",
            "        -8.0315e-02,  8.8629e-01, -4.0851e-01, -2.4656e+00, -1.2027e+00,\n",
            "         5.4768e-01, -1.6016e+00, -2.4273e+00,  5.5545e-01, -3.8055e-01,\n",
            "        -2.0514e+00,  3.3768e+00,  3.1911e+00,  6.6934e-01, -6.8485e-01,\n",
            "        -9.4824e-01, -3.6560e-01, -7.6281e-01,  2.1828e+00,  8.0137e-01,\n",
            "        -1.0065e+00, -1.2841e+00, -2.3672e+00, -3.1694e+00,  2.1263e+00,\n",
            "         1.2640e-01, -1.6896e+00,  2.6980e+00, -3.0841e+00,  4.0312e+00,\n",
            "        -2.8338e+00,  3.3884e-01,  9.7339e-03,  5.2670e-01,  1.9758e+00,\n",
            "        -7.3210e-02,  2.9077e-01, -2.9115e+00, -2.4019e+00,  7.0209e-01,\n",
            "        -4.1845e+00,  4.7319e-01,  1.1470e+00, -6.1824e-01, -7.0972e-01,\n",
            "        -3.9976e-01, -3.3723e-01, -6.5776e-01, -2.2191e+00,  1.5338e+00,\n",
            "         1.2756e+00,  2.7853e-01, -2.2764e+00, -5.6066e-01, -3.7203e+00,\n",
            "        -2.9087e+00, -6.8774e-01,  9.5925e-02,  1.8662e+00, -8.5131e-01,\n",
            "        -8.4491e-01, -3.8540e+00,  3.4257e-01,  2.5605e-01,  2.6890e+00,\n",
            "         2.6230e-01, -2.0013e+00,  5.3959e-01,  1.0952e+00, -1.3292e+00,\n",
            "         1.4825e+00, -5.9447e-01, -2.0439e+00, -1.2360e+00,  1.0510e+00,\n",
            "         6.4792e-01, -6.1280e-02,  1.2353e+00,  6.8331e-01,  3.8258e+00,\n",
            "        -1.7973e+00, -6.7225e-01, -2.5613e+00, -1.6505e+00,  1.1807e+00,\n",
            "        -1.2915e+00,  2.2603e+00, -4.0463e-01, -1.1887e+00, -2.3761e+00,\n",
            "         7.9948e-01, -9.1932e-01, -1.6115e+00, -1.9356e+00, -3.9246e+00,\n",
            "        -2.1024e+00,  2.1353e+00, -2.5580e-01,  4.8920e-01, -6.0455e-01,\n",
            "         1.1572e+00,  1.8442e+00, -4.0947e+00,  2.7045e-01, -2.1663e-01,\n",
            "         1.3759e+00, -1.4039e+00, -1.0381e+00,  4.7014e-02, -1.2816e-01,\n",
            "         3.2840e-01,  1.8626e+00,  3.2688e+00, -3.5490e-01, -2.1414e+00,\n",
            "        -4.3150e-01,  7.7571e-01,  3.6030e-02, -2.0637e+00,  3.1096e-01,\n",
            "         1.6417e+00,  2.6689e+00,  2.7126e-01,  8.3722e-01, -2.9802e+00,\n",
            "        -2.4621e-01,  2.4793e-01,  1.3218e-01, -4.3375e-01, -4.3000e-01,\n",
            "         6.5864e-01,  2.1320e+00, -3.2655e+00, -5.1030e-01,  4.9348e-01,\n",
            "        -1.8953e+00,  1.8287e+00, -1.6720e+00,  6.2937e-01, -1.6448e+00,\n",
            "        -1.6576e+00, -1.7353e-03, -6.8616e-01,  2.0157e+00, -4.9080e-01,\n",
            "         7.9296e-01, -6.6060e-01, -1.4477e+00,  5.7424e-01,  2.2925e-01,\n",
            "        -3.0096e-01, -2.0800e+00, -9.1668e-01, -1.9485e+00,  8.3571e-01,\n",
            "         1.2688e+00, -9.1500e-01,  5.4738e-01, -3.6898e+00, -9.1416e-01,\n",
            "         1.9859e+00, -2.5443e-01,  2.8499e-01,  2.0940e+00,  1.2096e+00,\n",
            "         2.1305e-01,  3.4639e+00,  9.6957e-02, -8.0251e-01,  2.7209e-01,\n",
            "         1.2201e+00,  7.1933e-01, -2.8366e+00, -2.7138e+00,  4.8013e-01,\n",
            "        -1.8521e+00,  2.9806e-01, -4.1023e+00,  1.8160e-01, -7.9910e-01,\n",
            "        -1.7319e+00, -9.6729e-01, -5.7994e-01, -8.2739e-01, -9.8500e-02,\n",
            "        -5.0437e-01,  1.5536e+00,  1.4906e+00, -1.2981e+00, -1.0559e-01,\n",
            "         2.9888e+00, -1.3633e+00, -3.7225e+00,  9.1919e-01, -2.5784e+00,\n",
            "        -3.0637e+00,  1.3358e+00, -1.4013e+00, -3.5383e-01, -1.1709e+00,\n",
            "        -7.4827e-01, -2.6182e-01, -6.0187e-01, -1.5588e+00,  1.3908e+00,\n",
            "        -2.3783e+00,  1.9797e+00,  3.3043e-01, -1.0162e-01,  2.4425e+00,\n",
            "         1.2643e+00, -6.6255e-01,  2.2883e+00,  1.8484e+00, -2.9061e+00,\n",
            "        -5.7552e-01, -5.1067e+00, -2.6354e+00,  2.1369e+00, -1.3468e+00,\n",
            "        -2.2597e+00,  4.3979e+00, -2.2586e+00, -1.0247e+00, -3.2042e+00,\n",
            "         6.7242e-01, -1.9923e+00, -2.0839e-01,  4.0523e-01, -2.9351e+00,\n",
            "         1.5748e+00, -9.1911e-01,  1.1530e+00, -9.1369e-01, -1.2579e+00,\n",
            "        -1.9512e+00,  1.0342e+00,  8.3940e-01,  1.6411e+00,  1.3352e+00,\n",
            "         7.9108e-01,  7.8882e-01,  1.2217e+00,  1.3786e+00, -7.8129e-01,\n",
            "        -1.3666e+00,  5.3830e+00,  5.1336e-01,  4.9093e-01,  5.2607e-01,\n",
            "         7.3226e-01,  2.2717e+00, -1.3198e+00,  9.3297e-01, -1.6310e+00,\n",
            "         2.4194e-01, -2.4816e-01, -4.8681e-01,  2.1142e+00,  1.4492e+00,\n",
            "         3.7196e-01,  1.4000e+00,  1.5157e+00, -3.6263e-01,  2.9181e-01,\n",
            "        -9.4070e-01, -2.2433e+00, -4.9349e-01, -4.5895e-01, -2.1173e+00,\n",
            "        -2.6541e+00, -4.2092e-01,  1.4906e+00,  6.6876e-01,  1.0796e+00,\n",
            "        -2.9840e-01,  1.3677e+00,  7.1267e-01,  2.7764e-01,  3.5629e-02,\n",
            "        -1.5738e+00,  6.9069e-01,  1.3072e+00, -6.9320e-01,  8.5233e-02,\n",
            "        -4.8829e-01, -1.4162e+00,  2.3646e+00, -8.0652e-01,  7.6336e-01,\n",
            "        -4.9398e+00, -6.1502e-01, -4.6479e-01, -2.4254e+00,  1.1545e+00,\n",
            "         6.3767e+00,  9.0615e-01, -4.1560e-01, -1.3360e+00,  2.3681e-01,\n",
            "         1.4628e+00,  2.6377e+00, -1.3075e+00,  8.5262e-01, -3.5924e-01,\n",
            "        -9.8999e-01, -1.2835e+00,  5.5973e-01,  2.0259e-02, -8.9757e-01,\n",
            "        -6.9378e-01, -1.9420e+00, -6.7268e-01,  1.2535e+00,  1.3385e+00,\n",
            "         8.7685e-01, -4.7692e-01,  1.7552e+00,  5.0891e-01, -1.3915e+00,\n",
            "        -8.7896e-01,  1.1590e+00, -1.0188e+00, -1.3283e+00, -3.7124e-01,\n",
            "        -1.0467e+00,  5.7418e-01,  1.5564e+00,  1.8520e+00, -4.1055e-01,\n",
            "        -2.0725e-01,  1.0545e+00,  1.8605e+00,  4.5566e-01,  9.1558e-01,\n",
            "         1.1520e+00, -1.4321e+00, -5.3181e-01, -1.4754e+00, -1.0050e+00,\n",
            "         1.2265e+00,  1.5208e+00,  5.0178e+00, -1.5195e+00, -5.4215e-01,\n",
            "        -6.5469e-01, -1.8719e+00, -3.6340e+00, -1.0437e+00,  7.0531e-02,\n",
            "        -2.3703e+00,  2.4597e+00, -1.3007e-01, -1.7993e+00, -7.5381e-01,\n",
            "        -1.0355e+00, -1.3386e+00, -2.9609e-01, -8.2644e-01,  2.7138e-01,\n",
            "         1.5865e+00, -7.2496e-01, -2.9765e-01, -9.2998e-01, -2.4289e+00,\n",
            "        -9.2125e-01,  4.7520e+00, -1.6786e+00,  8.6803e-01,  7.8073e-01,\n",
            "         1.6634e+00, -1.0699e+00,  1.3573e+00, -8.2479e-01, -1.9553e+00,\n",
            "         4.4847e-01, -2.2727e+00, -1.9742e+00, -1.3156e+00,  7.4103e-02,\n",
            "        -6.2437e-01, -1.2926e+00, -7.9400e-01,  1.4118e-01, -5.3716e-01,\n",
            "        -3.7518e+00,  2.5774e+00,  2.9513e+00,  1.1156e+00, -7.2821e-02,\n",
            "        -1.0611e+00,  1.7639e-01,  1.4932e+00, -1.3882e+00,  1.2884e+00,\n",
            "        -1.8537e+00, -2.2468e+00,  2.7331e-01, -2.0530e+00, -5.4501e-01,\n",
            "         8.9372e-01,  7.9943e-01,  1.3958e+00, -1.7464e-01, -5.9579e-01,\n",
            "         8.0432e-01, -1.3373e-01, -3.2305e+00, -2.1531e-01, -1.5620e+00,\n",
            "        -2.2869e+00, -3.0882e-01, -4.4396e+00, -6.2302e-01, -2.5379e+00,\n",
            "        -2.4711e+00, -3.3119e+00, -2.8567e+00, -2.9194e+00,  3.9099e+00,\n",
            "        -2.2019e+00, -2.0248e+00, -5.1720e-01, -4.8116e+00, -2.6824e+00,\n",
            "         7.0540e-01, -3.2399e-01,  8.4804e-01,  1.2203e+00,  1.4953e+00,\n",
            "        -1.9156e+00, -3.8725e+00, -4.3288e-01,  2.0204e+00, -2.2133e+00,\n",
            "        -3.7764e+00, -3.2412e+00, -1.0153e+00,  1.8910e+00,  4.7888e-01,\n",
            "        -2.6047e+00, -2.1483e+00, -2.8158e+00, -1.2958e+00, -1.0285e+00,\n",
            "        -2.7625e+00, -1.6156e+00, -4.0984e-01, -1.9464e-01, -2.4881e+00,\n",
            "        -1.3858e+00,  7.6183e-01, -2.6251e+00, -2.1394e+00, -5.1690e+00,\n",
            "        -2.3784e+00, -4.5178e-01, -4.3736e+00, -2.4076e-01, -8.7323e-01,\n",
            "         4.7064e-01,  1.5135e+00, -1.1392e+00, -3.5791e+00, -1.3164e-01,\n",
            "         2.2072e+00, -1.6691e+00,  7.5938e-01, -1.0788e+00, -7.7726e-01,\n",
            "        -6.3075e-01,  1.1566e-01,  1.1361e+00, -1.4198e+00, -8.3382e-01,\n",
            "        -1.6183e+00, -2.2295e+00,  6.9333e-01, -3.4876e+00, -1.4828e+00,\n",
            "        -1.3023e+00, -1.8196e-01, -5.2270e-01, -5.7323e+00, -1.8334e+00,\n",
            "        -6.5297e-01, -1.8076e+00, -2.9123e+00,  5.6004e-01,  2.5119e+00],\n",
            "       device='cuda:0')\n",
            "tensor([7.6847e-08, 1.6057e-08, 1.0425e-07, 9.6473e-09, 3.2046e-08, 4.5128e-07,\n",
            "        3.2911e-07, 6.5678e-07, 6.7224e-06, 1.7323e-07, 2.3314e-10, 2.2874e-09,\n",
            "        1.3006e-09, 6.5138e-10, 1.6789e-09, 6.7091e-10, 2.1419e-08, 1.0171e-07,\n",
            "        9.7432e-09, 4.4444e-08, 2.0694e-09, 3.3403e-08, 4.7506e-09, 2.1048e-08,\n",
            "        2.4735e-09, 1.1254e-08, 3.7613e-09, 1.9680e-08, 1.2032e-08, 3.0481e-07,\n",
            "        1.0119e-08, 1.8370e-08, 7.3747e-09, 1.2244e-08, 6.7219e-08, 2.4973e-09,\n",
            "        1.4461e-08, 2.3999e-09, 5.3604e-09, 4.8756e-09, 8.2075e-09, 1.9625e-09,\n",
            "        1.2231e-09, 2.8121e-10, 1.3106e-08, 1.3928e-08, 2.8319e-08, 9.0426e-09,\n",
            "        2.2445e-09, 1.9945e-08, 2.4314e-08, 2.3805e-08, 7.3938e-08, 3.2031e-08,\n",
            "        2.0779e-08, 4.2904e-09, 1.4631e-07, 1.3581e-08, 2.1785e-08, 7.3089e-09,\n",
            "        7.1319e-08, 1.1076e-08, 5.6350e-09, 1.2470e-08, 1.6665e-08, 2.5539e-08,\n",
            "        5.0256e-08, 2.0420e-08, 2.9521e-08, 1.3034e-09, 1.1268e-08, 4.1095e-08,\n",
            "        7.2683e-09, 5.8908e-09, 4.8044e-09, 8.7437e-09, 3.6063e-09, 1.6585e-09,\n",
            "        5.5598e-07, 1.6953e-07, 4.2190e-09, 4.7559e-08, 1.1188e-08, 1.1776e-08,\n",
            "        6.1936e-08, 3.5791e-08, 6.9168e-09, 2.4552e-08, 9.7376e-09, 7.4775e-07,\n",
            "        5.4075e-09, 1.9208e-09, 6.5155e-10, 4.5642e-09, 1.0948e-08, 7.2481e-10,\n",
            "        6.0777e-09, 6.2952e-09, 3.7361e-09, 4.6393e-08, 2.9675e-08, 5.5869e-09,\n",
            "        6.4148e-07, 5.4301e-09, 3.2079e-04, 1.8558e-07, 3.2277e-06, 2.4394e-09,\n",
            "        1.1331e-08, 1.0304e-09, 1.0116e-07, 7.3530e-09, 8.2067e-07, 7.8933e-08,\n",
            "        9.4545e-08, 1.6058e-07, 2.7669e-09, 1.7264e-08, 2.3257e-08, 1.1042e-08,\n",
            "        1.1980e-08, 2.1087e-08, 2.5511e-08, 2.7903e-08, 8.7971e-08, 1.8014e-08,\n",
            "        1.2453e-08, 2.2086e-07, 1.1721e-08, 9.8284e-08, 1.6819e-08, 7.2034e-10,\n",
            "        1.0731e-08, 7.8131e-11, 1.4604e-08, 3.0005e-09, 2.8622e-09, 1.6273e-09,\n",
            "        8.5773e-09, 2.2702e-09, 6.8741e-10, 2.0094e-09, 5.7245e-10, 1.0322e-08,\n",
            "        9.8428e-08, 3.8540e-08, 1.9268e-07, 8.0430e-09, 8.9403e-09, 4.6834e-08,\n",
            "        5.8119e-08, 1.2097e-05, 6.7518e-06, 1.5174e-05, 1.2594e-05, 2.1440e-07,\n",
            "        7.9870e-08, 2.2999e-05, 1.2492e-06, 3.9289e-08, 1.5479e-07, 2.5636e-08,\n",
            "        3.2421e-08, 1.8572e-08, 4.6618e-08, 1.3070e-09, 7.7260e-08, 1.3618e-08,\n",
            "        5.8684e-08, 1.1250e-05, 5.4229e-05, 1.1118e-07, 8.6952e-08, 1.7398e-06,\n",
            "        6.0286e-05, 7.1289e-07, 1.2045e-07, 2.0424e-06, 3.2291e-08, 2.2838e-07,\n",
            "        4.0673e-07, 7.7928e-08, 1.2023e-06, 2.0764e-07, 2.0334e-06, 3.2633e-05,\n",
            "        8.9076e-05, 1.2682e-07, 2.8587e-06, 1.2027e-06, 1.8992e-06, 2.9615e-08,\n",
            "        7.8836e-05, 5.4863e-06, 1.0359e-06, 3.7672e-07, 1.1715e-07, 2.2467e-07,\n",
            "        5.3146e-08, 3.5706e-05, 1.0674e-06, 3.7726e-07, 1.1010e-06, 2.3662e-03,\n",
            "        9.4384e-07, 1.7421e-07, 1.9600e-08, 1.3612e-05, 1.4672e-06, 4.2910e-08,\n",
            "        1.8057e-08, 7.7839e-08, 8.7825e-07, 1.0244e-07, 3.4738e-08, 3.9786e-07,\n",
            "        5.5073e-07, 5.9273e-07, 9.8902e-08, 6.2627e-08, 9.9473e-08, 1.3139e-08,\n",
            "        5.5037e-04, 2.5212e-04, 1.1478e-04, 1.3273e-06, 3.3318e-06, 5.0389e-06,\n",
            "        2.5403e-05, 3.5329e-05, 4.6263e-05, 1.5261e-04, 8.1632e-05, 1.5125e-06,\n",
            "        4.4616e-08, 2.0397e-05, 3.1946e-07, 5.0914e-08, 5.8260e-07, 4.9027e-07,\n",
            "        5.8258e-07, 9.2660e-08, 1.4392e-07, 5.0325e-08, 9.8479e-07, 2.6155e-07,\n",
            "        3.2610e-07, 4.8804e-06, 3.7783e-03, 4.7106e-04, 1.5159e-03, 1.2907e-06,\n",
            "        9.2530e-08, 4.5636e-07, 7.6621e-07, 9.4899e-07, 6.8212e-06, 4.6473e-03,\n",
            "        8.8469e-01, 5.6080e-03, 1.8643e-04, 3.4886e-03, 6.8399e-08, 2.2912e-05,\n",
            "        8.5038e-06, 2.2531e-06, 1.6695e-06, 3.5198e-06, 3.3851e-08, 2.6875e-04,\n",
            "        4.4308e-02, 2.4234e-06, 6.4465e-06, 1.8978e-05, 4.8041e-06, 6.2338e-08,\n",
            "        2.8377e-07, 1.2335e-05, 1.0387e-05, 4.5749e-02, 8.0613e-06, 4.6881e-06,\n",
            "        3.5448e-06, 4.6257e-05, 3.4063e-05, 2.0673e-06, 7.9799e-07, 7.0956e-05,\n",
            "        1.9636e-07, 1.3169e-06, 2.4542e-08, 3.4198e-07, 4.4081e-07, 2.6454e-07,\n",
            "        1.3185e-06, 4.3476e-07, 6.6614e-05, 9.7439e-08, 1.9866e-08, 1.2581e-07,\n",
            "        4.1762e-09, 3.3175e-08, 4.1075e-09, 3.5962e-09, 2.4821e-08, 4.5857e-09,\n",
            "        1.7747e-08, 3.8565e-08, 1.1047e-09, 1.2977e-08, 1.1708e-07, 1.8615e-08,\n",
            "        1.6235e-08, 1.5885e-08, 3.8702e-07, 6.9387e-09, 3.8531e-09, 4.8773e-08,\n",
            "        4.3590e-08, 1.6050e-10, 1.2722e-09, 7.1691e-09, 1.4521e-09, 4.2572e-09,\n",
            "        4.8134e-08, 1.3310e-08, 1.4696e-08, 6.4037e-07, 3.2280e-08, 7.4463e-08,\n",
            "        1.2078e-06, 1.6382e-05, 2.9158e-05, 1.7117e-05, 1.3556e-06, 1.1007e-07,\n",
            "        3.8547e-07, 1.1806e-07, 1.9315e-06, 2.0097e-07, 7.7596e-08, 1.6880e-06,\n",
            "        5.7756e-08, 4.6755e-09, 3.1803e-09, 1.7088e-07, 3.9426e-08, 3.9134e-09,\n",
            "        1.0216e-06, 2.8704e-08, 2.9073e-08, 6.8393e-10, 2.1072e-09, 9.5108e-08,\n",
            "        8.6472e-09, 5.0355e-05, 2.3082e-05, 1.4885e-06, 4.8370e-05, 1.8452e-05,\n",
            "        4.4487e-08, 8.3513e-06, 1.2435e-06, 7.5348e-08, 1.9608e-08, 4.7884e-08,\n",
            "        4.3087e-08, 1.4781e-08, 6.3618e-07, 1.7630e-08, 7.5421e-08, 1.8691e-07,\n",
            "        3.9745e-07, 5.9486e-07, 2.2318e-07, 3.3261e-08, 1.9037e-09, 9.6324e-07,\n",
            "        3.1209e-07, 1.2960e-07, 2.2338e-07, 6.8715e-08, 1.1995e-07, 2.2123e-07,\n",
            "        8.1601e-08, 5.2847e-09, 1.0177e-09, 2.9587e-06, 1.3411e-05, 4.0783e-08,\n",
            "        1.6160e-08, 1.5765e-07, 1.7903e-09, 3.7709e-09, 4.3734e-08, 1.1088e-08,\n",
            "        1.7375e-09, 3.8104e-09, 2.9979e-08, 4.9369e-08, 3.1087e-08, 4.2137e-08,\n",
            "        3.9314e-08, 5.5392e-10, 4.4309e-09, 1.0645e-07, 7.9619e-09, 5.7487e-08,\n",
            "        6.8337e-09, 4.4630e-08, 5.5854e-09, 1.0459e-07, 4.4095e-06, 9.0816e-09,\n",
            "        4.5131e-08, 1.2823e-08, 9.6424e-09, 3.8889e-08, 1.7960e-08, 2.0259e-07,\n",
            "        7.6138e-08, 2.8740e-08, 4.1432e-08, 1.8621e-08, 9.5181e-09, 2.2902e-07,\n",
            "        1.0771e-08, 6.8715e-07, 1.4136e-06, 4.8816e-07, 4.2048e-09, 4.9127e-08,\n",
            "        1.8653e-08, 5.2016e-08, 1.6420e-07, 3.8069e-06, 3.5413e-08, 6.2815e-08,\n",
            "        1.4884e-08, 6.8833e-07, 3.7252e-07, 8.1084e-08, 1.1180e-07, 1.2023e-07,\n",
            "        1.3636e-07, 6.8809e-08, 4.5173e-08, 1.9340e-08, 6.5063e-08, 4.2824e-08,\n",
            "        8.9169e-07, 1.3645e-08, 1.3995e-08, 5.4507e-08, 3.2526e-08, 6.2722e-07,\n",
            "        6.9573e-08, 4.5036e-07, 4.0062e-08, 3.5772e-08, 1.1608e-07, 4.5325e-08,\n",
            "        2.2920e-06, 2.2882e-05, 2.1028e-08, 1.4546e-08, 6.0385e-09, 3.1650e-09,\n",
            "        2.7491e-08, 1.9493e-07, 2.0410e-07, 6.7778e-08, 1.0023e-06, 3.3625e-07,\n",
            "        2.0625e-08, 5.6990e-08, 3.1847e-08, 6.5211e-08, 4.2658e-07, 8.7653e-07,\n",
            "        3.6226e-08, 5.8754e-09, 1.1143e-08, 8.9680e-08, 1.0481e-07, 1.9710e-08,\n",
            "        1.6372e-08, 3.5129e-08, 3.4397e-08, 2.0689e-07, 2.2467e-08, 3.3248e-07,\n",
            "        5.7457e-08, 1.9397e-08, 6.3396e-08, 2.3371e-08, 8.3024e-07, 3.8288e-08,\n",
            "        5.1265e-09, 8.1677e-08, 2.3957e-09, 2.5426e-07, 2.6857e-07, 2.5136e-08,\n",
            "        9.9991e-08, 2.7816e-08, 1.0199e-08, 1.6059e-07, 8.5957e-07, 1.3472e-08,\n",
            "        6.9767e-08, 1.8342e-07, 5.0247e-08, 6.4230e-09, 2.2709e-08, 1.3073e-07,\n",
            "        1.5239e-08, 6.6739e-09, 1.3175e-07, 5.1672e-08, 9.7186e-09, 2.2133e-06,\n",
            "        1.8383e-06, 1.4764e-07, 3.8116e-08, 2.9290e-08, 5.2450e-08, 3.5257e-08,\n",
            "        6.7067e-07, 1.6848e-07, 2.7632e-08, 2.0933e-08, 7.0871e-09, 3.1774e-09,\n",
            "        6.3381e-07, 8.5787e-08, 1.3956e-08, 1.1226e-06, 3.4605e-09, 4.2586e-06,\n",
            "        4.4446e-09, 1.0609e-07, 7.6340e-08, 1.2802e-07, 5.4527e-07, 7.0264e-08,\n",
            "        1.0111e-07, 4.1124e-09, 6.8456e-09, 1.5256e-07, 1.1514e-09, 1.2135e-07,\n",
            "        2.3805e-07, 4.0741e-08, 3.7179e-08, 5.0689e-08, 5.3960e-08, 3.9162e-08,\n",
            "        8.2180e-09, 3.5047e-07, 2.7071e-07, 9.9883e-08, 7.7603e-09, 4.3156e-08,\n",
            "        1.8316e-09, 4.1239e-09, 3.8005e-08, 8.3212e-08, 4.8866e-07, 3.2271e-08,\n",
            "        3.2478e-08, 1.6024e-09, 1.0649e-07, 9.7663e-08, 1.1126e-06, 9.8275e-08,\n",
            "        1.0218e-08, 1.2968e-07, 2.2602e-07, 2.0011e-08, 3.3294e-07, 4.1721e-08,\n",
            "        9.7916e-09, 2.1966e-08, 2.1626e-07, 1.4452e-07, 7.1107e-08, 2.6001e-07,\n",
            "        1.4972e-07, 3.4679e-06, 1.2531e-08, 3.8599e-08, 5.8365e-09, 1.4513e-08,\n",
            "        2.4620e-07, 2.0779e-08, 7.2470e-07, 5.0443e-08, 2.3030e-08, 7.0243e-09,\n",
            "        1.6817e-07, 3.0149e-08, 1.5089e-08, 1.0912e-08, 1.4931e-09, 9.2354e-09,\n",
            "        6.3957e-07, 5.8538e-08, 1.2331e-07, 4.1302e-08, 2.4050e-07, 4.7802e-07,\n",
            "        1.2596e-09, 9.9079e-08, 6.0876e-08, 2.9926e-07, 1.8570e-08, 2.6773e-08,\n",
            "        7.9240e-08, 6.6507e-08, 1.0499e-07, 4.8689e-07, 1.9868e-06, 5.3015e-08,\n",
            "        8.8826e-09, 4.9105e-08, 1.6422e-07, 7.8375e-08, 9.6004e-09, 1.0318e-07,\n",
            "        3.9040e-07, 1.0904e-06, 9.9160e-08, 1.7463e-07, 3.8393e-09, 5.9102e-08,\n",
            "        9.6872e-08, 8.6285e-08, 4.8995e-08, 4.9179e-08, 1.4607e-07, 6.3747e-07,\n",
            "        2.8862e-09, 4.5384e-08, 1.2384e-07, 1.1360e-08, 4.7065e-07, 1.4203e-08,\n",
            "        1.4186e-07, 1.4594e-08, 1.4409e-08, 7.5470e-08, 3.8065e-08, 5.6746e-07,\n",
            "        4.6278e-08, 1.6707e-07, 3.9051e-08, 1.7775e-08, 1.3425e-07, 9.5080e-08,\n",
            "        5.5953e-08, 9.4447e-09, 3.0229e-08, 1.0772e-08, 1.7437e-07, 2.6888e-07,\n",
            "        3.0279e-08, 1.3069e-07, 1.8883e-09, 3.0305e-08, 5.5082e-07, 5.8618e-08,\n",
            "        1.0053e-07, 6.1367e-07, 2.5344e-07, 9.3552e-08, 2.4149e-06, 8.3298e-08,\n",
            "        3.3885e-08, 9.9242e-08, 2.5610e-07, 1.5521e-07, 4.4323e-09, 5.0112e-09,\n",
            "        1.2219e-07, 1.1863e-08, 1.0185e-07, 1.2500e-09, 9.0656e-08, 3.4000e-08,\n",
            "        1.3377e-08, 2.8737e-08, 4.2332e-08, 3.3052e-08, 6.8509e-08, 4.5654e-08,\n",
            "        3.5748e-07, 3.3565e-07, 2.0643e-08, 6.8025e-08, 1.5015e-06, 1.9341e-08,\n",
            "        1.8275e-09, 1.8955e-07, 5.7377e-09, 3.5318e-09, 2.8751e-07, 1.8618e-08,\n",
            "        5.3072e-08, 2.3444e-08, 3.5773e-08, 5.8186e-08, 4.1413e-08, 1.5906e-08,\n",
            "        3.0376e-07, 7.0087e-09, 5.4740e-07, 1.0520e-07, 6.8295e-08, 8.6956e-07,\n",
            "        2.6767e-07, 3.8975e-08, 7.4532e-07, 4.8002e-07, 4.1347e-09, 4.2519e-08,\n",
            "        4.5786e-10, 5.4198e-09, 6.4059e-07, 1.9662e-08, 7.8911e-09, 6.1447e-06,\n",
            "        7.9000e-09, 2.7134e-08, 3.0688e-09, 1.4810e-07, 1.0310e-08, 6.1379e-08,\n",
            "        1.1337e-07, 4.0162e-09, 3.6512e-07, 3.0155e-08, 2.3949e-07, 3.0319e-08,\n",
            "        2.1490e-08, 1.0743e-08, 2.1265e-07, 1.7501e-07, 3.9018e-07, 2.8733e-07,\n",
            "        1.6676e-07, 1.6638e-07, 2.5651e-07, 3.0009e-07, 3.4611e-08, 1.9276e-08,\n",
            "        1.6456e-05, 1.2632e-07, 1.2352e-07, 1.2794e-07, 1.5723e-07, 7.3304e-07,\n",
            "        2.0200e-08, 1.9218e-07, 1.4798e-08, 9.6294e-08, 5.8986e-08, 4.6463e-08,\n",
            "        6.2618e-07, 3.2204e-07, 1.0967e-07, 3.0658e-07, 3.4418e-07, 5.2607e-08,\n",
            "        1.0122e-07, 2.9511e-08, 8.0220e-09, 4.6154e-08, 4.7776e-08, 9.0994e-09,\n",
            "        5.3197e-09, 4.9628e-08, 3.3564e-07, 1.4756e-07, 2.2254e-07, 5.6096e-08,\n",
            "        2.9682e-07, 1.5418e-07, 9.9794e-08, 7.8343e-08, 1.5668e-08, 1.5083e-07,\n",
            "        2.7942e-07, 3.7799e-08, 8.2327e-08, 4.6395e-08, 1.8344e-08, 8.0435e-07,\n",
            "        3.3749e-08, 1.6220e-07, 5.4099e-10, 4.0872e-08, 4.7498e-08, 6.6861e-09,\n",
            "        2.3983e-07, 4.4452e-05, 1.8710e-07, 4.9893e-08, 1.9874e-08, 9.5801e-08,\n",
            "        3.2643e-07, 1.0569e-06, 2.0449e-08, 1.7734e-07, 5.2785e-08, 2.8092e-08,\n",
            "        2.0946e-08, 1.3232e-07, 7.7148e-08, 3.0812e-08, 3.7777e-08, 1.0842e-08,\n",
            "        3.8582e-08, 2.6479e-07, 2.8829e-07, 1.8169e-07, 4.6925e-08, 4.3732e-07,\n",
            "        1.2576e-07, 1.8801e-08, 3.1391e-08, 2.4093e-07, 2.7293e-08, 2.0029e-08,\n",
            "        5.2156e-08, 2.6542e-08, 1.3424e-07, 3.5848e-07, 4.8179e-07, 5.0145e-08,\n",
            "        6.1450e-08, 2.1701e-07, 4.8590e-07, 1.1924e-07, 1.8887e-07, 2.3924e-07,\n",
            "        1.8054e-08, 4.4419e-08, 1.7290e-08, 2.7672e-08, 2.5775e-07, 3.4594e-07,\n",
            "        1.1422e-05, 1.6544e-08, 4.3962e-08, 3.9283e-08, 1.1630e-08, 1.9966e-09,\n",
            "        2.6624e-08, 8.1126e-08, 7.0648e-09, 8.8463e-07, 6.6380e-08, 1.2505e-08,\n",
            "        3.5575e-08, 2.6841e-08, 1.9824e-08, 5.6226e-08, 3.3083e-08, 9.9171e-08,\n",
            "        3.6942e-07, 3.6617e-08, 5.6138e-08, 2.9829e-08, 6.6631e-09, 3.0091e-08,\n",
            "        8.7556e-06, 1.4109e-08, 1.8010e-07, 1.6504e-07, 3.9894e-07, 2.5936e-08,\n",
            "        2.9375e-07, 3.3138e-08, 1.0699e-08, 1.1839e-07, 7.7893e-09, 1.0499e-08,\n",
            "        2.0285e-08, 8.1416e-08, 4.0492e-08, 2.0757e-08, 3.4174e-08, 8.7065e-08,\n",
            "        4.4182e-08, 1.7747e-09, 9.9509e-07, 1.4462e-06, 2.3068e-07, 7.0291e-08,\n",
            "        2.6163e-08, 9.0184e-08, 3.3651e-07, 1.8864e-08, 2.7421e-07, 1.1844e-08,\n",
            "        7.9941e-09, 9.9363e-08, 9.7029e-09, 4.3836e-08, 1.8478e-07, 1.6816e-07,\n",
            "        3.0530e-07, 6.3487e-08, 4.1666e-08, 1.6898e-07, 6.6138e-08, 2.9891e-09,\n",
            "        6.0957e-08, 1.5855e-08, 7.6794e-09, 5.5515e-08, 8.9213e-10, 4.0547e-08,\n",
            "        5.9749e-09, 6.3874e-09, 2.7553e-09, 4.3437e-09, 4.0797e-09, 3.7722e-06,\n",
            "        8.3611e-09, 9.9810e-09, 4.5072e-08, 6.1498e-10, 5.1711e-09, 1.5307e-07,\n",
            "        5.4679e-08, 1.7653e-07, 2.5615e-07, 3.3722e-07, 1.1132e-08, 1.5729e-09,\n",
            "        4.9037e-08, 5.7015e-07, 8.2659e-09, 1.7317e-09, 2.9572e-09, 2.7390e-08,\n",
            "        5.0095e-07, 1.2204e-07, 5.5890e-09, 8.8217e-09, 4.5254e-09, 2.0691e-08,\n",
            "        2.7030e-08, 4.7729e-09, 1.5027e-08, 5.0181e-08, 6.2229e-08, 6.2800e-09,\n",
            "        1.8910e-08, 1.6195e-07, 5.4761e-09, 8.9000e-09, 4.3017e-10, 7.0081e-09,\n",
            "        4.8120e-08, 9.5304e-10, 5.9425e-08, 3.1571e-08, 1.2104e-07, 3.4341e-07,\n",
            "        2.4199e-08, 2.1094e-09, 6.6276e-08, 6.8722e-07, 1.4245e-08, 1.6156e-07,\n",
            "        2.5703e-08, 3.4751e-08, 4.0234e-08, 8.4870e-08, 2.3546e-07, 1.8278e-08,\n",
            "        3.2840e-08, 1.4988e-08, 8.1336e-09, 1.5123e-07, 2.3115e-09, 1.7161e-08,\n",
            "        2.0556e-08, 6.3024e-08, 4.4825e-08, 2.4491e-10, 1.2087e-08, 3.9350e-08,\n",
            "        1.2403e-08, 4.1089e-09, 1.3236e-07, 9.3199e-07], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
        "print(output[0])\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "print(probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "turkish-disabled",
      "metadata": {
        "id": "turkish-disabled"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-16 13:18:18--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10472 (10K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt.8’\n",
            "\n",
            "imagenet_classes.tx 100%[===================>]  10,23K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-16 13:18:18 (214 MB/s) - ‘imagenet_classes.txt.8’ saved [10472/10472]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download ImageNet labels\n",
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "composite-differential",
      "metadata": {
        "id": "composite-differential"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Samoyed 0.8846860527992249\n",
            "Arctic fox 0.04574909061193466\n",
            "white wolf 0.044308312237262726\n",
            "Pomeranian 0.005607960745692253\n",
            "Great Pyrenees 0.004647292196750641\n"
          ]
        }
      ],
      "source": [
        "# Read the categories\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "# Show top categories per image\n",
        "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "for i in range(top5_prob.size(0)):\n",
        "    print(categories[top5_catid[i]], top5_prob[i].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "upper-income",
      "metadata": {
        "id": "upper-income"
      },
      "source": [
        "### Model Description\n",
        "\n",
        "Resnet models were proposed in \"Deep Residual Learning for Image Recognition\".\n",
        "Here we have the 5 versions of resnet models, which contains 18, 34, 50, 101, 152 layers respectively.\n",
        "Detailed model architectures can be found in Table 1.\n",
        "Their 1-crop error rates on imagenet dataset with pretrained models are listed below.\n",
        "\n",
        "| Model structure | Top-1 error | Top-5 error |\n",
        "| --------------- | ----------- | ----------- |\n",
        "|  resnet18       | 30.24       | 10.92       |\n",
        "|  resnet34       | 26.70       | 8.58        |\n",
        "|  resnet50       | 23.85       | 7.13        |\n",
        "|  resnet101      | 22.63       | 6.44        |\n",
        "|  resnet152      | 21.69       | 5.94        |\n",
        "\n",
        "### References\n",
        "\n",
        " - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e80c4a37a66a86446e48efe2a04e80f344c79c7819f7b8ac89b964afbe589337"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
